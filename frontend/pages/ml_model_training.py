import streamlit as st
import requests
import os
import pandas as pd
import logging
from typing import List, Optional, Dict, Any

logger = logging.getLogger(__name__)

st.set_page_config(page_title="ëª¨ë¸ í•™ìŠµ", page_icon="ğŸ§ ")

def get_columns_from_dataframe_path(file_path: str) -> List[str]:
    """Parquet íŒŒì¼ì—ì„œ ì»¬ëŸ¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        df = pd.read_parquet(file_path)
        return df.columns.tolist()
    except Exception as e:
        logger.error(f"Failed to read parquet file for columns: {e}", exc_info=True)
        st.error(f"ë°ì´í„° íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return []

def train_model_on_backend(
    file_path: str,
    target_column: str,
    model_type: str,
    features: Optional[List[str]] = None
) -> Optional[Dict[str, Any]]:
    """ë°±ì—”ë“œ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤."""
    api_url = os.getenv("API_URL")
    if not api_url:
        st.error("API_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    payload = {
        "file_path": file_path,
        "target_column": target_column,
        "model_type": model_type,
        "features": features
    }
    
    try:
        response = requests.post(f"{api_url.rstrip('/')}/ml/train-model/", json=payload, timeout=300) # Increased timeout
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"ëª¨ë¸ í•™ìŠµ ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        logger.error(f"Failed to request model training from backend: {e}", exc_info=True)
        return None

def main():
    st.title("ğŸ§  ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ")
    st.markdown("ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.")

    if not st.session_state.get("logged_in"):
        st.warning("ë¡œê·¸ì¸ í›„ ì´ìš© ê°€ëŠ¥í•œ í˜ì´ì§€ì…ë‹ˆë‹¤. ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        st.session_state["page"] = "login"
        st.switch_page("_login")
        st.stop()

    if not st.session_state.get("csv_analysis_complete") or not st.session_state.get("current_dataframe_path"):
        st.info("ë¨¼ì € 'í™ˆ' í˜ì´ì§€ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¶„ì„ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        st.session_state["page"] = "main_app" # Redirect to main app to upload CSV
        st.switch_page("app")
        st.stop()

    st.write(f"í˜„ì¬ í•™ìŠµì— ì‚¬ìš©í•  íŒŒì¼: **{os.path.basename(st.session_state.current_dataframe_path)}**")

    # ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
    all_columns = get_columns_from_dataframe_path(st.session_state.current_dataframe_path)
    if not all_columns:
        st.error("ë°ì´í„° íŒŒì¼ì—ì„œ ì»¬ëŸ¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    st.subheader("ëª¨ë¸ í•™ìŠµ ì„¤ì •")

    # íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ
    target_column = st.selectbox(
        "ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=["ì„ íƒ ì•ˆ í•¨"] + all_columns,
        key="ml_target_selector"
    )

    # ë¶„ì„ ë³€ìˆ˜ ì„ íƒ
    feature_columns = st.multiselect(
        "ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ë¶„ì„ ë³€ìˆ˜ë“¤ì„ ì„ íƒí•˜ì„¸ìš”",
        options=[col for col in all_columns if col != target_column and col != "ì„ íƒ ì•ˆ í•¨"],
        default=[col for col in all_columns if col != target_column and col != "ì„ íƒ ì•ˆ í•¨"],
        key="ml_feature_selector"
    )

    # AI ì¶”ì²œ ëª¨ë¸ ìœ í˜• í‘œì‹œ
    recommended_model_types = st.session_state.get("model_recommendations", {}).get("model_types", [])
    recommended_explanation = st.session_state.get("model_recommendations", {}).get("explanation", "")

    st.markdown("---")
    st.subheader("AI ì¶”ì²œ ëª¨ë¸ ìœ í˜•")
    if recommended_model_types:
        st.info(f"**ì¶”ì²œ ëª¨ë¸ ìœ í˜•:** {', '.join(recommended_model_types)}")
        st.write(recommended_explanation)
    else:
        st.warning("AI ëª¨ë¸ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. 'í™ˆ' í˜ì´ì§€ì—ì„œ CSV ë¶„ì„ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

    # ì‚¬ìš©ì ëª¨ë¸ ìœ í˜• ì„ íƒ
    st.markdown("---")
    st.subheader("ëª¨ë¸ ìœ í˜• ì„ íƒ")
    model_type_options = ["Classification", "Regression", "Clustering"]
    if "Time Series Forecasting" in recommended_model_types:
        model_type_options.append("Time Series Forecasting") # Add if recommended
    if "Recommendation" in recommended_model_types:
        model_type_options.append("Recommendation") # Add if recommended

    selected_model_type = st.selectbox(
        "í•™ìŠµí•  ëª¨ë¸ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”",
        options=model_type_options,
        key="model_type_selector"
    )

    st.markdown("---")
    if st.button("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
        if target_column == "ì„ íƒ ì•ˆ í•¨" and selected_model_type in ["Classification", "Regression"]:
            st.error("ë¶„ë¥˜ ë˜ëŠ” íšŒê·€ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        elif not feature_columns and selected_model_type in ["Classification", "Regression", "Clustering"]:
            st.error("ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ì„œëŠ” ë¶„ì„ ë³€ìˆ˜ë¥¼ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            with st.spinner(f"{selected_model_type} ëª¨ë¸ í•™ìŠµ ì¤‘..."):
                result = train_model_on_backend(
                    file_path=st.session_state.current_dataframe_path,
                    target_column=target_column if target_column != "ì„ íƒ ì•ˆ í•¨" else None,
                    model_type=selected_model_type,
                    features=feature_columns
                )
                if result:
                    st.success("ëª¨ë¸ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.json(result) # Display full result for now
                    st.session_state.trained_model_info = result # Store model info
                else:
                    st.error("ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # í•™ìŠµëœ ëª¨ë¸ ì •ë³´ í‘œì‹œ
    if st.session_state.get("trained_model_info"):
        st.markdown("---")
        st.subheader("í•™ìŠµëœ ëª¨ë¸ ì •ë³´")
        st.json(st.session_state.trained_model_info)

if __name__ == "__main__":
    main()
